{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progetto Cerrito - Riconoscimento e Classificazione celllule malate di malaria\n",
    "\n",
    "Import delle librerie necessarie al funzionamento del codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import backend as K\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import matplotlib.transforms as mtransforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impostiamo alcune variabili necessarie al funzionamento del codice:\n",
    "\n",
    "1. __train_data_dir__ ------------> La directory che contiene il dataset che utilizzeremo per fare in train del modello.\n",
    "2. __validation_data_dir__ -------> La directory contenente il dataset per la valutazione del modello (alcune immagini su cui faremo delle previsioni)\n",
    "3. __img_width, img_height__ -----> le dimensioni delle immagini con cui faremo lavorare il modello (rescaling delle stesse)\n",
    "4. __nb_train_samples__ ----------> number of samples we want to use in training\n",
    "5. __nb_validation_samples__ -----> number of samples we want to use for evaluating the model\n",
    "6. __epochs__ --------------------> numero di epochs con cui faremo il training del modello\n",
    "7. __batch_size__ ----------------> numero di samples che utilizzeremo per ogni singolo passo di training (weights adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_images/Dataset\n"
     ]
    }
   ],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "out.append_stdout(\"Son\")\n",
    "train_data_dir = os.path.join('cell_images', 'Dataset')\n",
    "validation_data_dir = os.path.join('cell_images', 'Validation')\n",
    "\n",
    "print(train_data_dir)\n",
    "\n",
    "img_width, img_height = 124, 124\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 200\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "First we set the input shape depending on or backend __image_data_format__.\n",
    "\n",
    "Initialize model with __Sequential()__ allows you to easily stack sequential layers of the network in order from input to output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0703 11:17:26.289039 140215874946880 deprecation_wrapper.py:119] From /opt/conda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a 2D convolutional layer to process input images.\n",
    "We need to pass some arguments to the Conv2D() layer function:\n",
    "\n",
    "1. The first argument is the number of outputs channels (as we have described in the model architecture).\n",
    "2. Then we need to pass the kernel_size (as we have seen a 5x5 moving window) and the strides in x and y directions (1, 1).\n",
    "3. We set the activation function as a rectified linear unit, and declare the input shape we defined before. (Input shape is only needed in the first layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 11:17:26.334770 140215874946880 deprecation_wrapper.py:119] From /opt/conda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0703 11:17:26.340975 140215874946880 deprecation_wrapper.py:119] From /opt/conda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a 2D max pooling layer.\n",
    "\n",
    "In the __MaxPooling2D()__ function we need to define the size of the pooling (2, 2) and the strides in x and y directions (2, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 11:17:27.626300 140215874946880 deprecation_wrapper.py:119] From /opt/conda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add an additional conv+MaxPooling layer accordingly to our model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungiamo ancora una conv2d e MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just finished building our convolutional layers, now we want to connect the output of convolutional layers to fully connected layers. \n",
    "\n",
    "First of all we need to flatten the output  with __Flatten()__ function.\n",
    "Next we add two __Dense()__ (fully connected) layers declaring output and activation function.\n",
    "Notice that the output of the final layer must match the number of category we whant to distinguish.\n",
    "In our case 4 simpsons characters (bart, homer, lisa, marge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 11:17:31.156970 140215874946880 deprecation_wrapper.py:119] From /opt/conda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0703 11:17:31.176141 140215874946880 deprecation.py:506] From /opt/conda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step of our model definition is the __model.compile()__\n",
    "here we need to pass some arguments:\n",
    "1. the loss function we want to minimize (keras provides a lot of loss functions - see [here](https://keras.io/losses/))\n",
    "2. an optimizer function to optimize our learning process (keras provides also a lot of loss functions - see [here](https://keras.io/optimizers/))\n",
    "3. a metric for the model evaluation. (as before keras provides a lot of loss functions - see [here](https://keras.io/metrics/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0703 11:17:37.001334 140215874946880 deprecation_wrapper.py:119] From /opt/conda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0703 11:17:37.041268 140215874946880 deprecation_wrapper.py:119] From /opt/conda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0703 11:17:37.051496 140215874946880 deprecation.py:323] From /opt/conda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation for training\n",
    "\n",
    "Keras provide us __ImageDataGenerator()__ class that let you generate always a fresh dataflow starting form a data directory to feed in our training-evaluating process.\n",
    "\n",
    "The images taken from the train_data_dir are randomly manipulated and feeded in to the model.\n",
    "\n",
    "This step is very important to provide a better training to the model.\n",
    "\n",
    "Per convenzione vengono assegnate le seguenti label, a partire dalla directory di input:\n",
    "1. unifected = 0\n",
    "2. parasitized = 1\n",
    "\n",
    "Applichiamo un split del dataset in per creare il dataset di test che corrisponde al 20% del dataset completo, applichiamo una seconda divisione del train set dividendolo al 50% tra train e validation, utilizzeremo il validation set per verificare il buon funzionamento della network in fase di predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "uninfected = os.listdir(train_data_dir+\"/Uninfected\")\n",
    "parasitized = os.listdir(train_data_dir+\"/Parasitized\")\n",
    "\n",
    "for i in uninfected:\n",
    "    data.append([train_data_dir+\"/Uninfected/\"+i,'Uninfected'])\n",
    "for i in parasitized:\n",
    "    data.append([train_data_dir+\"/Parasitized/\"+i,'Parasitized'])\n",
    "random.shuffle(data)\n",
    "image = [i[0] for i in data]\n",
    "label = [i[1] for i in data]\n",
    "del data\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(image, label, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.5, random_state=46)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better.\n",
    "\n",
    "These are just a few of the options available (for more, see the documentation). Let's quickly go over what we just wrote:\n",
    "\n",
    "rotation_range is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally\n",
    "rescale is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n",
    "shear_range is for randomly applying shearing transformations\n",
    "zoom_range is for randomly zooming inside pictures\n",
    "horizontal_flip is for randomly flipping half of the images horizontally --relevant when there are no assumptions of horizontal assymetry (e.g. real-world pictures).\n",
    "fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento immagini da una directory (e relative sottodirectory)\n",
    "\n",
    "Utilizzando il metodo flow_from_directory() passiamo tutti i dati al modello (caricamento massivo dei dati )secondo la struttura delle cartelle, facendo anche la resize delle immagini quando necessario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cell_images/Dataset/Parasitized/C99P60ThinF_IM...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cell_images/Dataset/Parasitized/C59P20thinF_IM...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cell_images/Dataset/Parasitized/C180P141NThinF...</td>\n",
       "      <td>Parasitized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cell_images/Dataset/Uninfected/C70P31_ThinF_IM...</td>\n",
       "      <td>Uninfected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename        Label\n",
       "0  cell_images/Dataset/Parasitized/C99P60ThinF_IM...  Parasitized\n",
       "1  cell_images/Dataset/Parasitized/C59P20thinF_IM...  Parasitized\n",
       "2  cell_images/Dataset/Parasitized/C180P141NThinF...  Parasitized\n",
       "3  cell_images/Dataset/Uninfected/C70P31_ThinF_IM...   Uninfected"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dataframe = pd.DataFrame({'Filename':X_train, 'Label':Y_train})\n",
    "x_testval_dataframe = pd.DataFrame({'Filename':X_test, 'Label':Y_test})\n",
    "x_validation_dataframe = pd.DataFrame({'Filename':X_val, 'Label':Y_val})\n",
    "\n",
    "x_train_dataframe.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creato il dataframe con la colonna path/filename e delle label associate, passiamo a creare (e a far caricare le immagini secondo i parametri associati a train_datagen) il modello.\n",
    "Il parametro directory viene posto a None, visto che nell'X_train e nel X_test sono già specificati i percorsi per ogni immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22321 validated image filenames belonging to 2 classes.\n",
      "Found 2756 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda3/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"Filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "X_train_generator = train_datagen.flow_from_dataframe(dataframe = x_train_dataframe,directory = None, x_col = 'Filename', y_col = 'Label', class_mode = 'binary', batch_size = batch_size, target_size=(img_width, img_height))\n",
    "X_testval_generator = train_datagen.flow_from_dataframe(dataframe = x_testval_dataframe,directory = None, x_col = 'Filename', y_col = 'Label', class_mode = 'binary', batch_size = batch_size, target_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 176,225\n",
      "Trainable params: 176,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed the model\n",
    "\n",
    "With fit_generator() we start the training process. \n",
    "1. First of all we need to pass the training data as the first argument.\n",
    "2. Then we declare the steps needed for each epoch, that will be obviously the number of training samples divided by the batch size.\n",
    "3. Next the number of epochs we whant to train the model.\n",
    "4. Then the validation data aka test datataset and the validation steps.\n",
    "\n",
    "verbose=2 mostra la progress bar per ogni epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 37s 297ms/step - loss: 0.6916 - acc: 0.5515 - val_loss: 0.6717 - val_acc: 0.6088\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 37s 294ms/step - loss: 0.6674 - acc: 0.6105 - val_loss: 0.6168 - val_acc: 0.6900\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.6300 - acc: 0.6705 - val_loss: 0.5210 - val_acc: 0.7837\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 37s 292ms/step - loss: 0.5599 - acc: 0.7670 - val_loss: 0.4497 - val_acc: 0.8553\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.4032 - acc: 0.8300 - val_loss: 0.3749 - val_acc: 0.8812\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.3436 - acc: 0.8770 - val_loss: 0.2824 - val_acc: 0.8875\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.3344 - acc: 0.8720 - val_loss: 0.3010 - val_acc: 0.8972\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.3175 - acc: 0.8955 - val_loss: 0.2807 - val_acc: 0.9000\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.3135 - acc: 0.8830 - val_loss: 0.2841 - val_acc: 0.9087\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.2981 - acc: 0.8980 - val_loss: 0.3426 - val_acc: 0.9075\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.3103 - acc: 0.9060 - val_loss: 0.2784 - val_acc: 0.8871\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.3068 - acc: 0.9020 - val_loss: 0.3724 - val_acc: 0.8925\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2840 - acc: 0.9130 - val_loss: 0.2873 - val_acc: 0.9012\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 35s 284ms/step - loss: 0.2647 - acc: 0.9215 - val_loss: 0.2865 - val_acc: 0.8947\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2846 - acc: 0.8985 - val_loss: 0.3880 - val_acc: 0.8938\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 35s 283ms/step - loss: 0.2810 - acc: 0.9075 - val_loss: 0.3654 - val_acc: 0.9075\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2708 - acc: 0.9105 - val_loss: 0.2300 - val_acc: 0.9275\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.3054 - acc: 0.9025 - val_loss: 0.2639 - val_acc: 0.9086\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2835 - acc: 0.9005 - val_loss: 0.2416 - val_acc: 0.9300\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.3100 - acc: 0.9045 - val_loss: 0.3489 - val_acc: 0.8812\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.3191 - acc: 0.8905 - val_loss: 0.2419 - val_acc: 0.9188\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.3169 - acc: 0.8965 - val_loss: 0.3800 - val_acc: 0.8962\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.3142 - acc: 0.9025 - val_loss: 0.2632 - val_acc: 0.9287\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2376 - acc: 0.9200 - val_loss: 0.2676 - val_acc: 0.9213\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.2808 - acc: 0.9050 - val_loss: 0.2960 - val_acc: 0.8988\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.3163 - acc: 0.9035 - val_loss: 0.2693 - val_acc: 0.9163\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.2893 - acc: 0.9010 - val_loss: 0.2680 - val_acc: 0.9150\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.3003 - acc: 0.9060 - val_loss: 0.2425 - val_acc: 0.9099\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2978 - acc: 0.9020 - val_loss: 0.2407 - val_acc: 0.9250\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.2912 - acc: 0.9105 - val_loss: 0.2242 - val_acc: 0.9237\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 35s 281ms/step - loss: 0.2841 - acc: 0.9005 - val_loss: 0.2575 - val_acc: 0.9099\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 35s 284ms/step - loss: 0.3278 - acc: 0.9045 - val_loss: 0.2855 - val_acc: 0.8912\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2687 - acc: 0.9030 - val_loss: 0.2522 - val_acc: 0.9150\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.2510 - acc: 0.9180 - val_loss: 0.2409 - val_acc: 0.9200\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.2758 - acc: 0.9095 - val_loss: 0.2652 - val_acc: 0.9137\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.3282 - acc: 0.8945 - val_loss: 0.2721 - val_acc: 0.9050\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2568 - acc: 0.9125 - val_loss: 0.2597 - val_acc: 0.9263\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 35s 284ms/step - loss: 0.2810 - acc: 0.9140 - val_loss: 0.2281 - val_acc: 0.9162\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2771 - acc: 0.9105 - val_loss: 0.2544 - val_acc: 0.9100\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.2819 - acc: 0.9125 - val_loss: 0.2275 - val_acc: 0.9225\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.2690 - acc: 0.9145 - val_loss: 0.3564 - val_acc: 0.9062\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.2900 - acc: 0.9115 - val_loss: 0.3066 - val_acc: 0.9226\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.2944 - acc: 0.9160 - val_loss: 0.2227 - val_acc: 0.9137\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.2604 - acc: 0.9110 - val_loss: 0.2898 - val_acc: 0.9125\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 35s 280ms/step - loss: 0.3028 - acc: 0.9105 - val_loss: 0.2886 - val_acc: 0.9137\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 35s 282ms/step - loss: 0.2656 - acc: 0.9135 - val_loss: 0.2609 - val_acc: 0.9213\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 36s 288ms/step - loss: 0.2676 - acc: 0.9270 - val_loss: 0.3307 - val_acc: 0.8925\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.2996 - acc: 0.9115 - val_loss: 0.2375 - val_acc: 0.9175\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 35s 280ms/step - loss: 0.3227 - acc: 0.9090 - val_loss: 0.2577 - val_acc: 0.9010\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 35s 280ms/step - loss: 0.2458 - acc: 0.9215 - val_loss: 0.2560 - val_acc: 0.9012\n"
     ]
    }
   ],
   "source": [
    "savemod = 1\n",
    "if os.path.exists('malaria_weights.h5') and os.path.exists('malaria_model_trained') and os.path.exists('validation_dataframe.csv'):\n",
    "    history = load_model('malaria_model_trained')\n",
    "    history.load_weights('malaria_weights.h5')\n",
    "    x_validation_dataframe.read_csv('validation_dataframe.csv')\n",
    "    savemod = 0\n",
    "\n",
    "else:\n",
    "    history = model.fit_generator(\n",
    "        X_train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=X_testval_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some graph\n",
    "Saving the model training process to a history variable is usefull to plot the metrics in a graph.\n",
    "In neural network training the training graph are the most usefull tool to benchmark our model and to do optimization of the architecture if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "\n",
    "After such a long wait for the learning process to come to an end dont forget to save the trained model.\n",
    "There are two way to save the model.\n",
    "1. Save the model weights (that are the result of traing) without model architecture. (this option is used mainly to switch the model to another framework\n",
    "2. Save the entire model (architecture and weights), so that it can be simply loaded up from keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights for further use\n",
    "if savemod:\n",
    "    model.save_weights('malaria_weights.h5')\n",
    "    model.save('malaria_model_trained')\n",
    "    x_validation_dataframe.to_csv('validation_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora testiamo il modello sul dataset di test (nota che il dataset di test è generato randomicamente anche dopo il training del modello)\n",
    "Selezioniamo rows * cols immagini dal dataset in maniera randomica e utilizziamo tale immagini per fare la predict su di loro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negative:  41\n",
      "False Positive:  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nrows = 10\\ncols = 5\\nig, ax = plt.subplots(rows, cols, figsize=(24, 24))\\ntoRnd = np.random.randint(low = 0, high = len(X_test), size = rows * cols)\\ncount=0\\nplt.figure(figsize=(64,64))\\nfor i in range(rows):\\n    for j in range(cols):\\n        charstr=\\'\\'\\n        img = Image.open(X_test[toRnd[i+j]])\\n        ax[i][j].imshow(img)\\n        img = img.convert(\"RGB\")\\n        img = img.resize((img_width, img_height), Image.ANTIALIAS)\\n        img = img_to_array(img)\\n        img = img/255.0\\n        img = img.reshape((1,) + img.shape)\\n        pred = model.predict(img)\\n        pred = pred.item(0)\\n        pred = np.round(pred, decimals = 3)\\n        charstr = \\'Uninfected: \\'+ str(pred) + \\'\\nInfected: \\' + str(np.round(1-pred, decimals = 3)) +\\'\\nOrig. Label: \\' + Y_test[toRnd[i+j]]\\n        ec = (0, .8, .1)\\n        fc = (0, .9, .2)\\n        count = count + 1\\n        ax[i][j].text(0, -10, charstr, size=10, rotation=0,\\n                ha=\"left\", va=\"top\", \\n                bbox=dict(boxstyle=\"round\", ec=ec, fc=fc, alpha = 1))\\nplt.setp(ax, xticks=[], yticks=[])\\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\\n'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "false_negative = 0\n",
    "false_positive = 0\n",
    "\n",
    "for row in x_validation_dataframe.itertuples(index=True, name='Pandas'):\n",
    "    #print(getattr(row, \"Filename\"), getattr(row, \"Label\"))\n",
    "    img = Image.open(getattr(row, \"Filename\"))\n",
    "    label = getattr(row, \"Label\")\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((img_width, img_height), Image.ANTIALIAS)\n",
    "    img = img_to_array(img)\n",
    "    img = img/255.0\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    pred = model.predict(img)\n",
    "    pred = pred.item(0)\n",
    "    pred = np.round(pred, decimals = 3)\n",
    "    if pred > 0.500 and label == 'Parasitized':\n",
    "        false_negative = false_negative + 1\n",
    "    if pred <= 0.500 and label == 'Uninfected':\n",
    "        false_positive = false_positive + 1\n",
    "    count=count + 1\n",
    "    if count >1000:\n",
    "        break;\n",
    "print(\"False Negative: \", false_negative)\n",
    "print(\"False Positive: \", false_positive)\n",
    "\"\"\"\n",
    "rows = 10\n",
    "cols = 5\n",
    "ig, ax = plt.subplots(rows, cols, figsize=(24, 24))\n",
    "toRnd = np.random.randint(low = 0, high = len(X_test), size = rows * cols)\n",
    "count=0\n",
    "plt.figure(figsize=(64,64))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        charstr=''\n",
    "        img = Image.open(X_test[toRnd[i+j]])\n",
    "        ax[i][j].imshow(img)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((img_width, img_height), Image.ANTIALIAS)\n",
    "        img = img_to_array(img)\n",
    "        img = img/255.0\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "        pred = model.predict(img)\n",
    "        pred = pred.item(0)\n",
    "        pred = np.round(pred, decimals = 3)\n",
    "        charstr = 'Uninfected: '+ str(pred) + '\\nInfected: ' + str(np.round(1-pred, decimals = 3)) +'\\nOrig. Label: ' + Y_test[toRnd[i+j]]\n",
    "        ec = (0, .8, .1)\n",
    "        fc = (0, .9, .2)\n",
    "        count = count + 1\n",
    "        ax[i][j].text(0, -10, charstr, size=10, rotation=0,\n",
    "                ha=\"left\", va=\"top\", \n",
    "                bbox=dict(boxstyle=\"round\", ec=ec, fc=fc, alpha = 1))\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
